---
title: 信息内容安全
icon: info
date: 2023-10-26
category: 其他
tag: 
    - 信息安全
---

## 1 信息安全导论

### 1.1 信息论基本观点

1. 系统是载体，信息是内涵

2. 信息不能脱离系统而孤立存在

3. 信息只有存储、传输、处理三种状态

### 1.2 信息系统安全的四个层次：

1. 设备安全：信息设备是信息系统的物质基础，设备安全是首要问题。

2. 数据安全：确保数据免受未授权的泄露、篡改和毁坏。

3. 内容安全：语义层次的要求

   ::: note
   - 政治：健康的社会，符合社会道德规范。
   - 法律：符合法律法规，不违反法律。
   - 道德：符合中华民族优良的道德规范，不损害社会利益。
   :::

4. 行为安全：主体行为的过程和结果是否危害信息安全

### 1.3 信息安全三大定律

1. 普遍性定律：哪里有信息，哪里就有信息安全问题。

2. 折中性定律：安全与方便是一对矛盾。

3. 就低性定律（木桶原理）：信息系统的安全性取决于最薄弱部分的安全性。

## 2 机器学习基础

### 2.1 相关概念

分类：预测值为离散值。

回归：预测值为连续值。

监督学习：训练数据有标记信息的学习任务，如分类、回归。

无监督学习：训练数据没有标记信息的学习任务，如聚类、关联规则。

### 2.2 奥卡姆剃刀原则

任何一个有效的机器学习算法必有其偏好。

机器学习算法在学习过程中对某种类型假设的偏好：简单有效原理（奥卡姆剃刀）

### 2.3 没有免费的午餐

NFL定理：一个算法a在某些问题上比b好，必存在另一些问题b比a好。

### 2.4 泛化误差和经验误差

泛化误差：在未来样本上的误差，在所有样本上的误差。

经验误差：在训练集上的误差，亦称训练误差。

测试误差：在测试集上的误差。

### 2.5 过拟合与欠拟合

过拟合：学习能力太强，把样本包含的不太一般的特征都学习到了。

欠拟合：学习能力太差，训练样本的一般性质尚未学习好。

### 2.6 划分方法

1. 留出法：数据集划分为两个互斥集合。单次的留出法结果往往不够稳定（数据分布一致性），一般要采用若干次随机划分，重复实验取平均值的做法。

2. 交叉验证法：数据集划分成k个互斥子集，用 k-1 个子集训练，1 个作测试，返回 k 次测试结果均值。（k=m：留一法。）划分为 K 个子集的过程具有随机性，因此K折交叉验证通常也要重复 p 次，称为 p 次k折交叉验证。

3. 自助法：自助采样，有放回采样，可重复采样。m 个样本的数据集 D，每次随机从 D 中挑选一个样本，将其拷贝放入 D'，然后再将该样本放回初始数据集 D 中，使得该样本在下次采样时仍有可能被采到。重复执行 m 次，就可以得到了包含 m 个样本的数据集 D'。D' 作为训练集， D-D' 作为测试集。（通过自助采样，初始样本集 D 中大约有 36.8% 的样本没有出现在 D' 中）

### 2.7 性能度量

1. 查准率和查全率
   ::: tip
   - P=TP/(TP+FP)
   - R=TP/(TP+FN)
   :::

2. F1=2PR/(P+R)

3. PR图：通过面积和平衡点比较性能

### 2.8 偏差-方差分解

泛化误差=偏差+方差+噪声

泛化性能由学习算法的能力、数据充分性和学习任务本身的难度共同决定。

## 3 机器学习-线性模型

### 3.1 线性判别分析LDA

基本思想：将样例投影到一条直线（低维空间）（也被视为监督降维技术）

优化目标：最大化广义瑞利商

![LDA优化目标](https://gitee.com/yindong-wen/picgo_img/raw/master/image/%E4%BF%A1%E6%81%AF%E5%86%85%E5%AE%B9%E5%AE%89%E5%85%A8%20(1).png)

### 3.2 类别不平衡问题

概念：不同类别的样本比例相差很大。

基本思路：y/(1-y) > (m+)/(m-)

常用方法（正例 900，反例 100 为例）：

1. 过采样：反例过少时，进行插值产生额外反例。

2. 欠采样：正例采出100个

3. 阈值移动：对预测值进行再缩放

![类别不平衡问题](https://gitee.com/yindong-wen/picgo_img/raw/master/image/%E4%BF%A1%E6%81%AF%E5%86%85%E5%AE%B9%E5%AE%89%E5%85%A8%20(2).png)

## 4 决策树模型

### 4.1 三个停止条件

1. 当前节点的样本全属于同一类别，无需划分

2. 当前属性集为空，或所有样本再所有属性上取值相同，无法划分

3. 当前节点包含的样本集为空，不能划分

### 4.2 信息增益和基尼指数

- 信息增益

  - 信息熵：度量样本集合纯度。

  ![信息熵公式](https://gitee.com/yindong-wen/picgo_img/raw/master/image/%E4%BF%A1%E6%81%AF%E5%86%85%E5%AE%B9%E5%AE%89%E5%85%A8%20(3).png)

  - 信息增益：划分前信息熵-属性划分后的信息熵。（缺点：对取值数目较多的属性有所偏好）

  ![信息增益公式](https://gitee.com/yindong-wen/picgo_img/raw/master/image/%E4%BF%A1%E6%81%AF%E5%86%85%E5%AE%B9%E5%AE%89%E5%85%A8%20(4).png)

  - 改进：增益率

  ![增益率公式](https://gitee.com/yindong-wen/picgo_img/raw/master/image/%E4%BF%A1%E6%81%AF%E5%86%85%E5%AE%B9%E5%AE%89%E5%85%A8%20(5).png)

- 基尼指数

  ![基尼指数公式](https://gitee.com/yindong-wen/picgo_img/raw/master/image/%E4%BF%A1%E6%81%AF%E5%86%85%E5%AE%B9%E5%AE%89%E5%85%A8%20(6).png)

## 5 信息内容预处理技术

### 5.1 预处理流程

1. 文本清洗：去除无关信息

2. 分词：分割成单独词

3. 去停用词：根据停用词列表去除某些词

4. 文本特征表示：文本转换为向量，如词袋、TF-IDF、Word2Vec

5. 文本特征选择

### 5.2 常见的文本表示方法

1. 独热

   ![独热编码](https://gitee.com/yindong-wen/picgo_img/raw/master/image/%E4%BF%A1%E6%81%AF%E5%86%85%E5%AE%B9%E5%AE%89%E5%85%A8%20(7).png)

2. 词语共现频次：高频词误导计算结果，无法反应词之间的高阶关系，仍然存在稀疏性问题。

   ![词语共现频次](https://gitee.com/yindong-wen/picgo_img/raw/master/image/%E4%BF%A1%E6%81%AF%E5%86%85%E5%AE%B9%E5%AE%89%E5%85%A8%20(8).png)

3. 点互信息：解决高频词误导计算结果的问题。

   ![点互信息](https://gitee.com/yindong-wen/picgo_img/raw/master/image/%E4%BF%A1%E6%81%AF%E5%86%85%E5%AE%B9%E5%AE%89%E5%85%A8%20(9).png)

### 5.3 奇异值分解（SVD）

解决无法反映词之间的高阶关系的问题。

### 5.4 TF-IDF（语义特征选择）

![TF-IDF公式](https://gitee.com/yindong-wen/picgo_img/raw/master/image/%E4%BF%A1%E6%81%AF%E5%86%85%E5%AE%B9%E5%AE%89%E5%85%A8%20(10).png)

优点：简单快速

缺点：单纯以词频衡量词的重要性，不够全面；无法体现词的位置信息

## 6 软件安全基础知识

### 6.1 软件漏洞分类

产生、发现、解决：0 day漏洞；1 day 漏洞；历史漏洞。

等级：低危漏洞、中危漏洞、高危漏洞。

### 6.2 内存破坏类漏洞

- 常见类型

  - 缓冲区溢出：程序向缓冲区写入超过其设定大小的数据时，会溢出到相邻内存，覆盖原有数据。
     ::: tip
     修复：
     限制输入字符串的长度
     使用安全函数
     检查输入参数的有效性等
     :::
  - 栈溢出：程序向某个变量写入字节超过了该变量申请的字节数，改变相邻栈中的值。
  - 堆溢出：程序向堆块写入字节超过了该块可用字节数，使得写入字节覆盖到物理相邻高地址的下一个堆块。
  - 格式化字符串漏洞：格式化操作，如printf、 sprintf、 fprintf等，未对用户输入内容进行过滤。
  - 释放后重用：内存释放后又被再次利用。
  - 内存泄漏：申请内存后，无法释放已申请的内存空间。
  - 空指针引用：空指针是未初始化或为赋值的指针。
  - 除零漏洞：一个数被零除时，产生算术异常。
  - 整数溢出：整数变量超出了所能表示的范围。
- 主要原因
  -  缓存区边界不正确处理
  - 非法指针解引用
  - 未初始化变量或成员
  - 动态内存分配不合理
  - 数据类型转换不当
### 6.3 CVE / CME / CVSS

- CVE 是用于标识和跟踪计算机安全漏洞的命名系统。

- CWE 是用于标识和描述常见软件和系统弱点的分类系统。

- CVSS 是用于评估和度量计算机安全漏洞严重程度的评分系统。

## 7 深度学习技术

### 7.1 神经网络

![神经网络结构](https://gitee.com/yindong-wen/picgo_img/raw/master/image/%E4%BF%A1%E6%81%AF%E5%86%85%E5%AE%B9%E5%AE%89%E5%85%A8%20(11).png)

参数量 = （5+4+2） + （3 x 5+5 x  4 + 4 x 2）

### 7.2 激活函数

1. 理想激活函数：阶跃函数，但不连续、不光滑。

2. 常用激活函数：sigmoid函数，容易出现梯度消失问题。

3. ReLU ：速度快，避免梯度弥散。对于负数输入会被归零，导致无法更新。

### 7.3 相关概念

1. 感知机：无隐藏层

2. 多层网络：包含隐层的网络

3. 前馈网络：不存在同层连接和跨层连接，即网络中无环（回路）。

4. 反向传播学习参数的过程：
   ::: tip
   初始化权重和偏置
   前向传播计算输出
   计算输出与期望输出之间的误差（代价函数）
   反向传播更新参数（梯度下降法）
   :::

### 7.4 链式求导法则

![链式求导法则](https://gitee.com/yindong-wen/picgo_img/raw/master/image/%E4%BF%A1%E6%81%AF%E5%86%85%E5%AE%B9%E5%AE%89%E5%85%A8%20(12).png)

### 7.5 卷积层和全连接层

卷积层特点：

1. 权值共享：卷积层可通过共享权重来减少参数，更好捕捉数据中的局部特征。

2. 局部连接：每个输出神经元，只与输入数据中一个局部区域内的神经元相连。

3. 不变性：由于卷积核的大小和权重是固定的。

全连接层相对卷积层的缺点：

1. 参数量大

2. 不具备平移不变性

### 7.6 缓解过拟合的方法

1. 早停

2. 正则化

### 7.7 self-attention

![self-attention](https://gitee.com/yindong-wen/picgo_img/raw/master/image/%E4%BF%A1%E6%81%AF%E5%86%85%E5%AE%B9%E5%AE%89%E5%85%A8%20(13).png)

### 7.8 LSTM 相对于原始 RNN 性能提升的原因

1. 长期依赖处理能力：原始 RNN 在处理长序列时容易遇到梯度消失或梯度爆炸的问题，导致难以捕捉长期依赖关系。LSTM 引入了门控机制，包括输入门、遗忘门和输出门，通过可学习的门控单元来控制信息的流动和保留。这使得 LSTM 能够更好地处理长序列数据中的长期依赖关系。

2. 梯度传播的稳定性：LSTM 中的门控机制可以有效地控制梯度的流动，避免梯度消失或梯度爆炸问题。这有助于更好地传播梯度信息，使得网络能够更稳定地学习和更新参数。
