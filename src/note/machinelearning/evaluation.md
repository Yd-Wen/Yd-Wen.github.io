---
date: 2023-09-30
title: 2 模型选择与评估
icon: base
category:
  - 机器学习
tag:
  - 基础
---

## 2.1 三种误差与两种拟合

- 训练误差/经验误差：训练集上的误差

- 测试误差：测试集上的误差

- 泛化误差：出训练集外的所有样本的误差

- 过拟合：训练集的一般性质学的太好，将样本的特殊性质作为一般性质

::: tip
解决方法：
1. 早停：训练误差降低，验证误差升高则停止训练。
2. 正则化：误差目标函数增加一项描述网络复杂度的部分。
:::

- 欠拟合：训练集的一般性质尚未学好

::: tip
解决方法：
1. 决策树拓展分支
2. 神经网络增加训练轮数
:::

## 2.2 数据集划分方法

下面介绍常用的数据集划分方法。

### 2.2.1 留出法

将数据集划分为两个互斥的子集，重复划分取平均值

::: note
为保证两个子集数据分布一致，多次随机划分；训练/测试比例为2：1 - 4：1 。
:::

### 2.2.2 交叉验证法

将数据集划分为k个大小相似的互斥子集，每次用k-1个子集作为训练集，余下一个作为测试集，返回k次测试平均值。

::: note
- 为保证每个子集数据分布一致，多次随机划分；训练/测试比例为1：1 - 3：1 。
- p次k折交叉验证法：重复p次划分。
- k=m时，称为留一法。
:::

### 2.2.3 自助法
对数据集有放回采用m次得到训练集，余下作为测试集
::: note
- 训练/测试比例为1：1 - 3：1 。
:::

## 2.3 评估指标
### 2.3.1 错误率和精度

- 错误率：预测错误样本占总样本的比例。

- 精度：预测正确样本占总样本的比例。

### 2.3.2 查准率、查全率和 F1

- 查准率 P = TP / ( TP + FP )

- 查全率 R = TP / ( TP  + FN )

- F1 = 2PR / ( P + R )

### 2.3.3 ROC与AUC

ROC（受试者工作特征）：以真正例率为纵轴，假正例率为横轴，将分类阈值设置为每个样本的预测值，当前为真正例点上移（移动1/m+），当前为假正例点右移（移动1/m-），绘制图形。

AUC：曲线围绕的面积。

::: important
- 真正例率：TPR = TP / (  TP + FN )
- 假正例率：FPR = FP / ( TN + FP ) 
:::

- 四类样例:

|      | +    | -    |
| ---- | ---- | ---- |
| +    | TP   | FN   |
| -    | FP   | TN   |

- 四个度量:

| 中文名   | 英文名 | 公式              |
| -------- | ------ | ----------------- |
| 查准率   | P      | TP / ( TP + FP )  |
| 查全率   | R      | TP / ( TP  + FN ) |
| 真正例率 | TPR    | TP / ( TP  + FN ) |
| 假正例率 | FPR    | FP / ( TN + FP )  |

## 2.4 比较检验

- Friedman 检验：根据 k 个算法在 N 个数据集上的性能进行排序，赋予序值，计算每个算法的平均序值。变量计算后超出阈值，则以某个置信度拒绝 k 个算法性能相同的假设，进行 Nemenyi 后续检验。

- Nemenyi 检验：计算两个平均序值的差异，超过阈值，则以相同置信度拒绝两个算法性能相同的假设。

- Friedman 检验图：线段交叠时无显著差异。序值小，性能高。

## 2.5 偏差方差分解

泛化误差 = 偏差 + 方差 + 噪声

泛化能力由学习算法的能力、数据的充分性和学习任务本身的难度共同决定。

::: important
- 偏差：模型预测值与真实值的期望误差。
- 方差：模型预测值的变化范围。
:::

偏差-方差窘境：

1. 训练不足时，拟合能力不强，偏差主导；
2. 训练加深时，拟合能力增强，方差主导；
3. 训练充足时，拟合能力非常强，训练数据轻微扰动会导致学习器显著变化，容易过拟合。
